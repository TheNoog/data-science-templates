classdef DataPoint
    properties
        features
        label
    end
    methods
        function obj = DataPoint(features, label)
            obj.features = features;
            obj.label = label;
        end
    end
end

classdef Dataset
    properties
        data
    end
    methods
        function obj = Dataset(data)
            obj.data = data;
        end
    end
end

function dataset = loadDataset()
    % Load the dataset
    data = {};

    % Your code to load the data from a file or any other source goes here
    % Add each data point as a DataPoint object to the data cell array

    dataset = Dataset(data);
end

function [priors, likelihoods] = trainNaiveBayes(dataset)
    numDataPoints = length(dataset.data);
    numClasses = 3; % Number of classes in your dataset
    numFeatures = 4; % Number of features in your dataset

    classCounts = zeros(1, numClasses);
    priors = zeros(1, numClasses);
    likelihoods = zeros(numClasses, numFeatures);

    % Count the occurrences of each class label
    for i = 1:numDataPoints
        classCounts(dataset.data{i}.label) = classCounts(dataset.data{i}.label) + 1;
    end

    % Calculate priors
    for i = 1:numClasses
        priors(i) = classCounts(i) / numDataPoints;
    end

    % Calculate likelihoods
    for i = 1:numClasses
        for j = 1:numFeatures
            featureSum = 0.0;
            featureCount = 0;

            % Sum the values of the feature for the current class
            for k = 1:numDataPoints
                if dataset.data{k}.label == i
                    featureSum = featureSum + dataset.data{k}.features(j);
                    featureCount = featureCount + 1;
                end
            end

            % Calculate the average of the feature for the current class
            likelihoods(i, j) = featureSum / featureCount;
        end
    end
end

function predictedLabel = predict(dataPoint, priors, likelihoods)
    numClasses = length(priors);
    numFeatures = size(likelihoods, 2);
    maxPosterior = 0.0;
    predictedLabel = -1;

    % Calculate the posterior probability for each class
    for i = 1:numClasses
        posterior = priors(i);

        for j = 1:numFeatures
            posterior = posterior * exp(-(dataPoint.features(j) - likelihoods(i, j))^2 / 2);
        end

        % Update the predicted class if the posterior is higher than the current maximum
        if posterior > maxPosterior
            maxPosterior = posterior;
            predictedLabel = i;
        end
    end
end

% Main program
dataset = loadDataset();
[priors, likelihoods] = trainNaiveBayes(dataset);

% Example usage: Predict the class label for a new data point
newDataPoint = DataPoint([5.1, 3.5, 1.4, 0.2], 0);

predictedLabel = predict(newDataPoint, priors, likelihoods);
disp("Predicted Label: " + predictedLabel);
